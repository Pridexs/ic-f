---
title: "chapter8"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(fpp)
require(fma)
```

### 1. Figure 8.24 shows the ACFs for 36 random numbers, 360 random numbers and for 1,000 random number

> (a) Explain the differences among these figures. Do they all indicate the data are white noise?
> (b) Why are the critical values at different distances from the mean of zero? Why are the autocorrelations different in each figure when they each refer to white noise?

1. Sim, as 3 figuras indicam que que os dados são white noise (nenhum pico fora da região critica, nenhum padrão evidente)
2. Os valores críticos mudam pois há diferentes quantidades de observações em cada set. Quanto mais observações, menos white noise se tem, logo a região critíca deve ser menor para verificar se realmente os dados são white-noise.

### 2. A classic example of a non-stationary series is the daily closing IBM stock prices (data set ibmclose). Use R to plot the daily closing prices for IBM stock and the ACF and PACF. Explain how each plot shows the series is non-stationary and should be differenced.

```{r}
plot(ibmclose)
par(mfrow=c(1,2))
acf(ibmclose)
pacf(ibmclose)
```

1. ACF: A demora para cair para 0 mostra que a série não é estacionária e deve ser diferenciada.
2. PACF: Quando o primeiro valor é proximo de um e os demais estão entre a linha crítica é sinal de que a série deve ser diferenciada.

### 3. For the following series, find an appropriate Box-Cox transformation and order of differencing in order to obtain stationary data.

> usnetelec

```{r}
par(mfrow=c(1,1))
plot(usnetelec)
usnetelec.lambda <- BoxCox.lambda(usnetelec)
usnetelec.boxcox <- BoxCox(usnetelec, lambda=usnetelec.lambda)
usnetelec.diff <- diff(usnetelec.boxcox)
plot (usnetelec.diff)
par(mfrow=c(1,2))
Acf(usnetelec.diff, main="ACF usnetelec com Box-Cox")
Acf(diff(usnetelec), main="ACF usnetelec sem Box-Cox")
Pacf(usnetelec.diff, main="PACF usnetelec com Box-Com")
Pacf(diff(usnetelec), main="PACF usnetelec sem Box-Cox")
```

* A série não é sazonal logo não é necessário aplicar o diff com lag.
* Usando diff uma vez foi o suficiente, aplicação do Box-Cox ajuda na stacionariedade (O autor não realizou a transformação)

> usgdp

```{r}
par(mfrow=c(1,1))
plot(usgdp)
usgdp.lambda <- BoxCox.lambda(usgdp)
usgdp.boxcox <- BoxCox(usgdp, lambda=usgdp.lambda)
usgdp.diff <- diff(usgdp.boxcox)
plot (usgdp.diff)
par(mfrow=c(1,2))
Acf(usgdp.diff)
Pacf(usgdp.diff)
```

* Série não sazonal
* Box-Cox + diff foi o suficiente para deixar ACF como white-noise (embora tenha alguns picos fora da região crítica)

> mcopper

```{r}
par(mfrow=c(1,1))
plot(mcopper)
mcopper.lambda <- BoxCox.lambda(mcopper)
mcopper.boxcox <- BoxCox(mcopper, lambda=mcopper.lambda)
plot(mcopper.boxcox)
mcopper.diff <- diff(mcopper.boxcox)
plot (mcopper.diff)
par(mfrow=c(1,2))
Acf(mcopper.diff)
Pacf(mcopper.diff)
```

* ACF cai para 0 rapidamente
* PACF e ACF possui alguns valores fora da região crítica mas pode ser considerado estacionária

> enplanements

```{r}
par(mfrow=c(1,1))
plot(enplanements)
Acf(enplanements)
enplanements.lambda <- BoxCox.lambda(enplanements)
enplanements.boxcox <- BoxCox(enplanements, lambda=enplanements.lambda)
enplanements.diff <- diff(enplanements.boxcox, lag=12)
plot (enplanements.diff)
par(mfrow=c(1,2))
Acf(enplanements.diff)
Pacf(enplanements.diff)
```

* Aqui temos um comportamento sazonal com frequencia anual, logo diff(, lag=12)
* acf ainda mostra que não está estacionaria

```{r}
enplanements.diff2 <- diff(diff(enplanements.boxcox), lag=12)
par(mfrow=c(1,1))
plot(enplanements.diff2)
Acf(enplanements.diff2, lag.max=80)
Pacf(enplanements.diff2, lag.max=80)
```

* Agora, embora a pontos fora da região crítica, a série parece estar estacionaria (acf caindo para 0 rapidamente, PACF sem um pico chegando a 1)

> visitors

```{r}
par(mfrow=c(1,1))
plot(visitors)
visitors.lambda <- BoxCox.lambda(visitors)
visitors.boxcox <- BoxCox(visitors, lambda=visitors.lambda)
Acf(visitors.boxcox)
```

* Sazonalidade anual (lag=12)

```{r}
visitors.diff <- diff(visitors.boxcox, lag=12)
plot (visitors.diff)
par(mfrow=c(1,2))
Acf(visitors.diff)
Pacf(visitors.diff)
```

* Um diff não foi suficiente, ACF não cai rapidamente para 0, PACF com pico alto em 0

```{r}
visitors.diff2 <- diff(diff(visitors.boxcox), lag=12)
par(mfrow=c(1,1))
plot(visitors.diff2)
Acf(visitors.diff2, lag.max=80)
Pacf(visitors.diff2, lag.max=80)
```

* Tanto o ACF e o PACF mostram grandes picos foram da zona crítica
* Não apresentam um padrão
* Pode ser considerado como estacionaria(?)

### (4) For the enplanements data, write down the differences you chose above using backshift operator notation.

$(1-B)(1-B^{12})y_t$

### (5) Use R to simulate and plot some data from simple ARIMA models.

> a) Use the following R code to generate data from an AR(1) model with $\phi_1=0.6$ and $\sigma^2=1$. The process starts with $y_0 = 0$.

> b) Produce a time plot for the series. How does the plot change as you change $\phi_1$?

```{r}
e <- rnorm(100)
AR1 = function(e, phi)
{
  y <- ts(numeric(100))
  for(i in 2:100) {
    y[i] <- phi*y[i-1] + e[i]
  }
  return(y)
}
plot(AR1(e, 0.6))
plot(AR1(e, -0.8))
plot(AR1(e, -0.3))
plot(AR1(e, 0))
plot(AR1(e, 0.3))
plot(AR1(e, 0.8))
```

* Para $\phi < 0$ temos grandes picos já que os valores anteriores estão sendo negados.
* Quando $\phi > 0$ as previsões tendem a ser mais parecidas com o valor anterior.

> c) Write your own code to generate data from an MA(1) model with $\theta_1=0.6$ and $\sigma^2=1$.

> d) Produce a time plot for the series. How does the plot change as you change θ1θ1?

```{r}
MA1 = function(e, theta)
{
  y <- ts(numeric(100))
  for(i in 2:100) {
    y[i] <- e[i] + theta*e[i-1]
  }
  return(y)
}

plot(MA1(e, 0.6))
plot(MA1(e, -0.8))
plot(MA1(e, 0.8))
```

> e) Generate data from an ARMA(1,1) model with $\phi_1$ = 0.6 and $\theta_1=0.6$ and $\sigma^2=1$.

```{r}
ARMA11 = function(e, phi, theta)
{
  y <- ts(numeric(100))
  for(i in 2:100) {
    y[i] <- (phi * y[i-1]) + (theta * e[i-1]) + e[i]
  }
  return(y)
}


plot(ARMA11(e, 0.6, 0.6))
```

> f) Generate data from an AR(2) model with $\phi_1=−0.8$ and $\phi_2=0.3$.

> g) Graph the latter two series and compare them.

```{r}
AR2 = function(e, phi1, phi2)
{
  y <- ts(numeric(100))
  for(i in 3:100) {
    y[i] <- (phi1 * y[i-1]) + (phi2 * y[i-2]) + e[i]
  }
  return(y)
}

plot(AR2(e, -0.8, 0.3))
```

ARMA11 está dentro de um limite e segue os padrões da série. Já o AR2 está completamente fora dos limites.

### (6) Consider the number of women murdered each year (per 100,000 standard population) in the United States (data set wmurders).

> a) By studying appropriate graphs of the series in R, find an appropriate ARIMA(p,d,qp,d,q) model for these data.

```{r}
plot(wmurders)

wmurders.lambda <- BoxCox.lambda(wmurders)
wmurders.boxcox <- BoxCox(wmurders, lambda=wmurders.lambda)

plot(wmurders.boxcox)
acf(wmurders.boxcox, lag.max=100)
pacf(wmurders.boxcox, lag.max=100)
```

Os resultados do ACF e do PACF mostram que a série não é estacionario, logo devemos diferenciala (d++)

Como não temos sazonalidade, não precisamos se preocupar com o lag

```{r}
plot(diff(wmurders.boxcox))
acf(diff(wmurders.boxcox), lag.max=100)
pacf(diff(wmurders.boxcox), lag.max=100)
```

O pico no lag2 tanto no ACF como no PACF sugere que devemos aplicar um modelo AR(2) ou MA(2).

Logo deve-se aplicar um modelo ARIMA(0,1,2) ou ARIMA(2,1,0)

Escolherei ARIMA(0,1,2)

> b) Should you include a constant in the model? Explain.

?

> c) Write this model in terms of the backshift operator.

$(1 - B)y_t = (1 + \theta_1B + \theta_2B^2)e_t$

> d) Fit the model using R and examine the residuals. Is the model satisfactory?

```{r}
(wmurders.arima <- Arima(wmurders, c(0,1,2), lambda=wmurders.lambda))

wmurders.arima.res <- residuals(wmurders.arima)

acf(wmurders.arima.res, lag.max=50)
pacf(wmurders.arima.res, lag.max=50)
hist(wmurders.arima.res)

Box.test(wmurders.arima.res, type="L")
shapiro.test(wmurders.arima.res)
```

Os dados parecem ser white no ACF e no PACF e o teste de Ljung nos da uma certeza maior.

Também parecem estar normalmente-distribuidos, o que o teste de shapiro comprova.

Logo, pode ser dito que o modelo se adequou aos dados.

> e) Forecast three times ahead. Check your forecasts by hand to make sure you know how they have been calculated.

```{r}

wmurders.arima.fcast <- forecast (wmurders.arima, h=3)
plot (wmurders.arima.fcast)

```

> f) Create a plot of the series with forecasts and prediction intervals for the next three periods shown.

> g) Does auto.arima give the same model you have chosen? If not, which model do you think is better?

```{r}
(wmurders.autoarima <- auto.arima(wmurders, lambda=wmurders.lambda))
plot(forecast(wmurders.autoarima, h=3))
```

auto.arima escolheu o  modelo ARIMA(1,2,1).

É dificil dizer qual modelo é o melhor, o auto.arima escolheu um modelo que apresenta uma tendencia decrescente, mas não parece muito que os dados vão continuar caindo linearmente como o forecast mostra, logo o melhor modelo provavelmente é o ARIMA(0,1,2)

