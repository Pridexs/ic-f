---
title: "chapter8"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(fpp)
require(fma)
```

### 1. Figure 8.24 shows the ACFs for 36 random numbers, 360 random numbers and for 1,000 random number

> (a) Explain the differences among these figures. Do they all indicate the data are white noise?
> (b) Why are the critical values at different distances from the mean of zero? Why are the autocorrelations different in each figure when they each refer to white noise?

1. Sim, as 3 figuras indicam que que os dados são white noise (nenhum pico fora da região critica, nenhum padrão evidente)
2. Os valores críticos mudam pois há diferentes quantidades de observações em cada set. Quanto mais observações, menos white noise se tem, logo a região critíca deve ser menor para verificar se realmente os dados são white-noise.

### 2. A classic example of a non-stationary series is the daily closing IBM stock prices (data set ibmclose). Use R to plot the daily closing prices for IBM stock and the ACF and PACF. Explain how each plot shows the series is non-stationary and should be differenced.

```{r}
plot(ibmclose)
par(mfrow=c(1,2))
acf(ibmclose)
pacf(ibmclose)
```

1. ACF: A demora para cair para 0 mostra que a série não é estacionária e deve ser diferenciada.
2. PACF: Quando o primeiro valor é proximo de um e os demais estão entre a linha crítica é sinal de que a série deve ser diferenciada.

### 3. For the following series, find an appropriate Box-Cox transformation and order of differencing in order to obtain stationary data.

> usnetelec

```{r}
par(mfrow=c(1,1))
plot(usnetelec)
usnetelec.lambda <- BoxCox.lambda(usnetelec)
usnetelec.boxcox <- BoxCox(usnetelec, lambda=usnetelec.lambda)
usnetelec.diff <- diff(usnetelec.boxcox)
plot (usnetelec.diff)
par(mfrow=c(1,2))
Acf(usnetelec.diff, main="ACF usnetelec com Box-Cox")
Acf(diff(usnetelec), main="ACF usnetelec sem Box-Cox")
Pacf(usnetelec.diff, main="PACF usnetelec com Box-Com")
Pacf(diff(usnetelec), main="PACF usnetelec sem Box-Cox")
```

* A série não é sazonal logo não é necessário aplicar o diff com lag.
* Usando diff uma vez foi o suficiente, aplicação do Box-Cox ajuda na stacionariedade (O autor não realizou a transformação)

> usgdp

```{r}
par(mfrow=c(1,1))
plot(usgdp)
usgdp.lambda <- BoxCox.lambda(usgdp)
usgdp.boxcox <- BoxCox(usgdp, lambda=usgdp.lambda)
usgdp.diff <- diff(usgdp.boxcox)
plot (usgdp.diff)
par(mfrow=c(1,2))
Acf(usgdp.diff)
Pacf(usgdp.diff)
```

* Série não sazonal
* Box-Cox + diff foi o suficiente para deixar ACF como white-noise (embora tenha alguns picos fora da região crítica)

> mcopper

```{r}
par(mfrow=c(1,1))
plot(mcopper)
mcopper.lambda <- BoxCox.lambda(mcopper)
mcopper.boxcox <- BoxCox(mcopper, lambda=mcopper.lambda)
plot(mcopper.boxcox)
mcopper.diff <- diff(mcopper.boxcox)
plot (mcopper.diff)
par(mfrow=c(1,2))
Acf(mcopper.diff)
Pacf(mcopper.diff)
```

* ACF cai para 0 rapidamente
* PACF e ACF possui alguns valores fora da região crítica mas pode ser considerado estacionária

> enplanements

```{r}
par(mfrow=c(1,1))
plot(enplanements)
Acf(enplanements)
enplanements.lambda <- BoxCox.lambda(enplanements)
enplanements.boxcox <- BoxCox(enplanements, lambda=enplanements.lambda)
enplanements.diff <- diff(enplanements.boxcox, lag=12)
plot (enplanements.diff)
par(mfrow=c(1,2))
Acf(enplanements.diff)
Pacf(enplanements.diff)
```

* Aqui temos um comportamento sazonal com frequencia anual, logo diff(, lag=12)
* acf ainda mostra que não está estacionaria

```{r}
enplanements.diff2 <- diff(diff(enplanements.boxcox), lag=12)
par(mfrow=c(1,1))
plot(enplanements.diff2)
Acf(enplanements.diff2, lag.max=80)
Pacf(enplanements.diff2, lag.max=80)
```

* Agora, embora a pontos fora da região crítica, a série parece estar estacionaria (acf caindo para 0 rapidamente, PACF sem um pico chegando a 1)

> visitors

```{r}
par(mfrow=c(1,1))
plot(visitors)
visitors.lambda <- BoxCox.lambda(visitors)
visitors.boxcox <- BoxCox(visitors, lambda=visitors.lambda)
Acf(visitors.boxcox)
```

* Sazonalidade anual (lag=12)

```{r}
visitors.diff <- diff(visitors.boxcox, lag=12)
plot (visitors.diff)
par(mfrow=c(1,2))
Acf(visitors.diff)
Pacf(visitors.diff)
```

* Um diff não foi suficiente, ACF não cai rapidamente para 0, PACF com pico alto em 0

```{r}
visitors.diff2 <- diff(diff(visitors.boxcox), lag=12)
par(mfrow=c(1,1))
plot(visitors.diff2)
Acf(visitors.diff2, lag.max=80)
Pacf(visitors.diff2, lag.max=80)
```

* Tanto o ACF e o PACF mostram grandes picos fora da zona crítica
* Não apresentam um padrão
* Pode ser considerado como estacionaria(?)

### (4) For the enplanements data, write down the differences you chose above using backshift operator notation.

$(1-B)(1-B^{12})y_t$

### (5) Use R to simulate and plot some data from simple ARIMA models.

> a) Use the following R code to generate data from an AR(1) model with $\phi_1=0.6$ and $\sigma^2=1$. The process starts with $y_0 = 0$.

> b) Produce a time plot for the series. How does the plot change as you change $\phi_1$?

```{r}
e <- rnorm(100)
AR1 = function(e, phi)
{
  y <- ts(numeric(100))
  for(i in 2:100) {
    y[i] <- phi*y[i-1] + e[i]
  }
  return(y)
}
plot(AR1(e, 0.6))
plot(AR1(e, -0.8))
plot(AR1(e, -0.3))
plot(AR1(e, 0))
plot(AR1(e, 0.3))
plot(AR1(e, 0.8))
```

* Para $\phi < 0$ temos grandes picos já que os valores anteriores estão sendo negados.
* Quando $\phi > 0$ as previsões tendem a ser mais parecidas com o valor anterior.

> c) Write your own code to generate data from an MA(1) model with $\theta_1=0.6$ and $\sigma^2=1$.

> d) Produce a time plot for the series. How does the plot change as you change θ1θ1?

```{r}
MA1 = function(e, theta)
{
  y <- ts(numeric(100))
  for(i in 2:100) {
    y[i] <- e[i] + theta*e[i-1]
  }
  return(y)
}

plot(MA1(e, 0.6))
plot(MA1(e, -0.8))
plot(MA1(e, 0.8))
```

> e) Generate data from an ARMA(1,1) model with $\phi_1$ = 0.6 and $\theta_1=0.6$ and $\sigma^2=1$.

```{r}
ARMA11 = function(e, phi, theta)
{
  y <- ts(numeric(100))
  for(i in 2:100) {
    y[i] <- (phi * y[i-1]) + (theta * e[i-1]) + e[i]
  }
  return(y)
}


plot(ARMA11(e, 0.6, 0.6))
```

> f) Generate data from an AR(2) model with $\phi_1=−0.8$ and $\phi_2=0.3$.

> g) Graph the latter two series and compare them.

```{r}
AR2 = function(e, phi1, phi2)
{
  y <- ts(numeric(100))
  for(i in 3:100) {
    y[i] <- (phi1 * y[i-1]) + (phi2 * y[i-2]) + e[i]
  }
  return(y)
}

plot(AR2(e, -0.8, 0.3))
```

ARMA11 está dentro de um limite e segue os padrões da série. Já o AR2 está completamente fora dos limites.

### (6) Consider the number of women murdered each year (per 100,000 standard population) in the United States (data set wmurders).

> a) By studying appropriate graphs of the series in R, find an appropriate ARIMA(p,d,qp,d,q) model for these data.

```{r}
plot(wmurders)

wmurders.lambda <- BoxCox.lambda(wmurders)
wmurders.boxcox <- BoxCox(wmurders, lambda=wmurders.lambda)

plot(wmurders.boxcox)
acf(wmurders.boxcox, lag.max=100)
pacf(wmurders.boxcox, lag.max=100)
```

Os resultados do ACF e do PACF mostram que a série não é estacionario, logo devemos diferenciala (d++)

Como não temos sazonalidade, não precisamos se preocupar com o lag

```{r}
plot(diff(wmurders.boxcox))
acf(diff(wmurders.boxcox), lag.max=100)
pacf(diff(wmurders.boxcox), lag.max=100)
```

O pico no lag2 tanto no ACF como no PACF sugere que devemos aplicar um modelo AR(2) ou MA(2).

Logo deve-se aplicar um modelo ARIMA(0,1,2) ou ARIMA(2,1,0)

Escolherei ARIMA(0,1,2)

> b) Should you include a constant in the model? Explain.

?

> c) Write this model in terms of the backshift operator.

$(1 - B)y_t = (1 + \theta_1B + \theta_2B^2)e_t$

> d) Fit the model using R and examine the residuals. Is the model satisfactory?

```{r}
(wmurders.arima <- Arima(wmurders, c(0,1,2), lambda=wmurders.lambda))

wmurders.arima.res <- residuals(wmurders.arima)

acf(wmurders.arima.res, lag.max=50)
pacf(wmurders.arima.res, lag.max=50)
hist(wmurders.arima.res)

Box.test(wmurders.arima.res, type="L")
shapiro.test(wmurders.arima.res)
```

Os dados parecem ser white no ACF e no PACF e o teste de Ljung nos da uma certeza maior.

Também parecem estar normalmente-distribuidos, o que o teste de shapiro comprova.

Logo, pode ser dito que o modelo se adequou aos dados.

> e) Forecast three times ahead. Check your forecasts by hand to make sure you know how they have been calculated.

```{r}

wmurders.arima.fcast <- forecast (wmurders.arima, h=3)
plot (wmurders.arima.fcast)

log(wmurders)
wmurders.arima$residuals
```

(By hand no caderno)
Coeficientes: -0.09 e 0.37

> f) Create a plot of the series with forecasts and prediction intervals for the next three periods shown.

> g) Does auto.arima give the same model you have chosen? If not, which model do you think is better?

```{r}
(wmurders.autoarima <- auto.arima(wmurders, lambda=wmurders.lambda))
plot(forecast(wmurders.autoarima, h=3))
```

auto.arima escolheu o  modelo ARIMA(1,2,1).

É dificil dizer qual modelo é o melhor, o auto.arima escolheu um modelo que apresenta uma tendencia decrescente, mas não parece muito que os dados vão continuar caindo linearmente como o forecast mostra, logo o melhor modelo provavelmente é o ARIMA(0,1,2)

### (7) Consider the quarterly number of international tourists to Australia for the period 1999–2010. (Data set austourists.)

> a) Describe the time plot

```{r} 
plot(austourists)
```

Série sazonal com tendência crescente. Sazonlidade de 12 meses. Alguns valores fora do padrão entre 2001 e 2003.

A sazonlidade parece aumentar conforme a série cresce, logo teremos que aplicar uma transformaçao na mesma.

> b) What can you learn from the ACF graph?
> c) What can you learn from the PACF graph?

```{r}
laustourists <- log(austourists)
plot(laustourists)
Acf(laustourists)
Pacf(laustourists)
```

Acf não cai rapidamente para zero, o que sugere que é necessário diferenciar.

Pacf ?

> d) Produce plots of the seasonally differenced data $(1−B^4)Y_t$. What model do these graphs suggest?

```{r}
plot(diff(laustourists, 4))
Acf(diff(laustourists, 4))
Pacf(diff(laustourists, 4))
```

AR(1), MA(1)
ARIMA(0,1,1)(0,0,1) ou ARIMA(1,1,0)(0,0,1)

#### 8. Consider the total net generation of electricity (in billion kilowatt hours) by the U.S. electric industry (monthly for the period 1985–1996). (Data set usmelec.) In general there are two peaks per year: in mid-summer and mid-winter.

> a) Examine the 12-month moving average of this series to see what kind of trend is involved.
> b) Do the data need transforming? If so, find a suitable transformation.

```{r}
plot(usmelec)
lines(ma(usmelec, 12), col="red")
```

Sim, elas precisam ser transformadas pois a dimensão da sazonalidade aumenta conforme a série vai crescendo.

```{r} 
usmelec.lambda <- BoxCox.lambda(usmelec)
usmelec.lambda
```

Como o lambda é considerável, não fazemos uma simples transformação logarítimica.

```{r}
usmelec2 <- BoxCox(usmelec, usmelec.lambda)
plot(usmelec2)
```

> Are the data stationary? If not, find an appropriate differencing which yields stationary data.

Não, os dados claramente não são estacionários.

```{r}
usmelec.diff <- diff(usmelec, lag=12)
tsdisplay(usmelec.diff)
```

Os dados parecem estar estacionários (embora talvez o ACF demore um pouco para cair a zero)

> d) Identify a couple of ARIMA models that might be useful in describing the time series. Which of your models is the best according to their AIC values?

ARIMA(1,0,0)(0,1,1)
ARIMA(2,0,0)(0,1,1)
ARIMA(1,0,1)(0,1,1)
ARIMA(0,0,1)(0,1,1)

```{r}
usmelec.f1 <- Arima(usmelec, c(1,0,0), c(0,1,1), lambda = usmelec.lambda)
usmelec.f2 <- Arima(usmelec, c(2,0,0), c(0,1,1), lambda = usmelec.lambda)
usmelec.f3 <- Arima(usmelec, c(1,0,1), c(0,1,1), lambda = usmelec.lambda)
usmelec.f4 <- Arima(usmelec, c(0,0,1), c(0,1,1), lambda = usmelec.lambda)
usmelec.f5 <- Arima(usmelec, c(3,0,0), c(0,1,1), lambda = usmelec.lambda)
usmelec.f6 <- Arima(usmelec, c(1,0,2), c(0,1,1), lambda = usmelec.lambda)
usmelec.f6 <- Arima(usmelec, c(1,0,2), c(0,1,1), lambda = usmelec.lambda)


c(usmelec.f1$aicc, usmelec.f2$aicc, usmelec.f3$aicc, usmelec.f4$aicc, usmelec.f5$aicc, usmelec.f6$aicc)
```

O menor valor é o fit6: ARIMA(1,0,2)(0,1,1)

> e) Estimate the parameters of your best model and do diagnostic testing on the residuals. Do the residuals resemble white noise? If not, try to find another ARIMA model which fits better.

```{r}
tsdisplay(usmelec.f6$residuals)
hist(usmelec.f6$residuals)
Box.test(usmelec.f6$residuals, lag=24, type="Lj", fitdf=4 )
```

Embora tenha 1 pico considerável tanto no ACF quanto no PACF, os dados parecem ser white noise. Ljung não deu uma resposta muito definitva.

#### 9. For the mcopper data:

> a) if necessary, find a suitable Box-Cox transformation for the data;
> b) fit a suitable ARIMA model to the transformed data using auto.arima();

```{r}
plot(mcopper)
mcopper.lambda <- BoxCox.lambda(mcopper)
plot(BoxCox(mcopper, mcopper.lambda))
(mcopper.aur <- auto.arima(mcopper, lambda = mcopper.lambda))
```

auto.arima sugere ARIMA(0,1,1)

> c) try some other plausible models by experimenting with the orders chosen;

ARIMA(0,1,7)
ARIMA(0,1,5)
ARIMA(4,1,0)


```{r}
Acf(diff(mcopper))
Pacf(diff(mcopper))

mcopper.f1 <- Arima(mcopper, c(0,1,7), lambda = mcopper.lambda)
mcopper.f2 <- Arima(mcopper, c(0,1,5), lambda = mcopper.lambda)
mcopper.f3 <- Arima(mcopper, c(4,1,0), lambda = mcopper.lambda)
mcopper.f4 <- Arima(mcopper, c(4,1,5), lambda = mcopper.lambda)


c(mcopper.aur$aicc, mcopper.f1$aicc, mcopper.f2$aicc, mcopper.f3$aicc, mcopper.f4$aicc)
```

O melhor método ainda é o proposto pelo auto.arima

> d) choose what you think is the best model and check the residual diagnostics;

```{r}
tsdisplay(mcopper.aur$residuals)
hist(mcopper.aur$residuals)
Box.test(mcopper.aur$residuals, lag=12, type="Lj")

```

Os resíduos parecem ser white noise, e estão normalmente distribuidos, o que indica ser um bom modelo.

> e) produce forecasts of your fitted model. Do the forecasts look reasonable?
> f) compare the results with what you would obtain using ets() (with no transformation).

```{r}
mcopper.fcast <- forecast(mcopper.aur, h=20)
plot(mcopper.fcast)

mcopper.ets <- ets(mcopper)
mcopper.ets.fcast <- forecast(mcopper.ets, h = 20)
plot(mcopper.ets.fcast)
```

Embora as diferenças não sejam tão grandes, o ets parece ter obtido um resultado melhor.